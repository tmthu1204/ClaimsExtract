{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13238231,"sourceType":"datasetVersion","datasetId":8388959},{"sourceId":13239060,"sourceType":"datasetVersion","datasetId":8389206},{"sourceId":13239945,"sourceType":"datasetVersion","datasetId":8389464}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cài OpenJDK 8\n!apt-get update -qq\n!apt-get install -y openjdk-8-jdk-headless\n\n\n\n# --- Chuyển mặc định sang Java 8 ---\n!update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java 2000\n!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n\n# --- Kiểm tra phiên bản ---\n!java -version\n\n# --- Export JAVA_HOME để thư viện khác nhận biết ---\nimport os\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\nos.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\nos.environ[\"JVM_PATH\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server/libjvm.so\"\n\n!echo $JAVA_HOME\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-02T10:29:43.446956Z","iopub.execute_input":"2025-10-02T10:29:43.447266Z","iopub.status.idle":"2025-10-02T10:29:49.369501Z","shell.execute_reply.started":"2025-10-02T10:29:43.447243Z","shell.execute_reply":"2025-10-02T10:29:49.368760Z"}},"outputs":[{"name":"stdout","text":"W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nopenjdk-8-jdk-headless is already the newest version (8u462-ga~us1-0ubuntu2~22.04.2).\n0 upgraded, 0 newly installed, 0 to remove and 189 not upgraded.\nopenjdk version \"1.8.0_462\"\nOpenJDK Runtime Environment (build 1.8.0_462-8u462-ga~us1-0ubuntu2~22.04.2-b08)\nOpenJDK 64-Bit Server VM (build 25.462-b08, mixed mode)\n/usr/lib/jvm/java-8-openjdk-amd64\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"## ==============================\n# 1️⃣ Copy project zip lên Kaggle và setup\n# ==============================\n\n# Hiển thị nội dung input\n!ls /kaggle/input/claims-33\n\n# Copy folder/zip từ input về working dir\n!cp -r /kaggle/input/claims-33 ./ClaimsExtract33\n\n# Rename folder nếu cần\n!mv \"./ClaimsExtract33/Claim Extraction\" ./ClaimsExtraction33\n\n# Vào thư mục root của project\n%cd ./ClaimsExtraction33\n!pwd\n!ls -l\n\n# ==============================\n# 2️⃣ Setup sys.path để import modules\n# ==============================\nimport sys, os\n\nROOT_DIR = os.getcwd()\nprint(f\"ROOT_DIR: {ROOT_DIR}\")\n\n# Thêm ROOT_DIR vào path để import models, utils\nif ROOT_DIR not in sys.path:\n    sys.path.insert(0, ROOT_DIR)\nprint(\"sys.path[0:3]:\", sys.path[:3])\n\n!pip install -r requirements.txt\n# 5. Cài thư viện cần thiết\n!pip install -q transformers datasets evaluate rouge_score sacrebleu\n\n# ==============================\n# 3️⃣ Train contextualize model\n# ==============================\n!python scripts/train_contextualize.py\n\n# Sau khi train xong, folder model sẽ là ví dụ: \"vit5-base-contextualize-claim\"\nMODEL_DIR = os.path.join(ROOT_DIR, \"vit5-base-contextualize-claim\")\nprint(\"Model dir:\", MODEL_DIR)\nassert os.path.exists(MODEL_DIR), \"Folder model không tồn tại!\"\n\n# ==============================\n# 4️⃣ Download & setup VnCoreNLP\n# ==============================\n!wget -q https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n!wget -q https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.dict -P vncorenlp/models/wordsegmenter/\n\n\n# Tạo folder vncorenlp theo đúng cấu trúc\n!mkdir -p vncorenlp/models/wordsegmenter\n!mv VnCoreNLP-1.1.1.jar vncorenlp/\n!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/\n!mv wordsegmenter.dict vncorenlp/models/wordsegmenter/\n\nVNCORENLP_DIR = os.path.join(ROOT_DIR, \"vncorenlp\")\nprint(\"VnCoreNLP dir:\", VNCORENLP_DIR)\nassert os.path.exists(VNCORENLP_DIR), \"Folder vncorenlp không tồn tại!\"\n\n# ==============================\n# 5️⃣ Extract claims\n# ==============================\n!python Test/extract_claims.py\n\n# ==============================\n# 6️⃣ Predict contextualized claims\n# ==============================\n!python Test/predict_contextualize.py\n\n# ==============================\n# 7️⃣ Check output\n# ==============================\nimport pandas as pd\ncontextualized_csv = os.path.join(ROOT_DIR, \"Test\", \"data\", \"contextualized_claims.csv\")\nif os.path.exists(contextualized_csv):\n    df = pd.read_csv(contextualized_csv)\n    print(f\"Total claims extracted: {len(df)}\")\n    display(df.head())\nelse:\n    print(\"Chưa có file output contextualized_claims.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T10:29:49.370961Z","iopub.execute_input":"2025-10-02T10:29:49.371175Z","iopub.status.idle":"2025-10-02T10:47:20.656529Z","shell.execute_reply.started":"2025-10-02T10:29:49.371154Z","shell.execute_reply":"2025-10-02T10:47:20.655837Z"}},"outputs":[{"name":"stdout","text":"'Claim Extraction'\n/kaggle/working/ClaimsExtraction33\n/kaggle/working/ClaimsExtraction33\ntotal 127024\n-rw-r--r-- 1 root root      665 Oct  2 10:29 colab_setup.py\n-rw-r--r-- 1 root root     4213 Oct  2 10:29 colab_train.py\n-rw-r--r-- 1 root root      619 Oct  2 10:29 contextualize_claims.py\n-rw-r--r-- 1 root root     4524 Oct  2 10:29 cpu_train_contextualize.py\ndrwxr-xr-x 2 root root     4096 Oct  2 10:29 data\n-rw-r--r-- 1 root root     2364 Oct  2 10:29 extract_claims.py\n-rw-r--r-- 1 root root     4489 Oct  2 10:29 kaggle_train_contextualize.py\ndrwxr-xr-x 2 root root     4096 Oct  2 10:29 models\n-rw-r--r-- 1 root root 89026560 Oct  2 10:29 OpenJDK8U-jdk_x64_windows_hotspot_8u462b08.msi\ndrwxr-xr-x 4 root root     4096 Oct  2 10:29 py_vncorenlp\n-rw-r--r-- 1 root root      409 Oct  2 10:29 README.md\n-rw-r--r-- 1 root root       77 Oct  2 10:29 requirements.txt\n-rw-r--r-- 1 root root 13551616 Oct  2 10:29 rustup-init.exe\ndrwxr-xr-x 2 root root     4096 Oct  2 10:29 scripts\n-rw-r--r-- 1 root root      602 Oct  2 10:29 setup_vncorenlp.py\n-rw-r--r-- 1 root root     3881 Oct  2 10:29 small_model_train.py\ndrwxr-xr-x 3 root root     4096 Oct  2 10:29 Test\ndrwxr-xr-x 2 root root     4096 Oct  2 10:29 utils\n-rw-r--r-- 1 root root 27412575 Oct  2 10:29 VnCoreNLP-1.1.1.jar\nROOT_DIR: /kaggle/working/ClaimsExtraction33\nsys.path[0:3]: ['/kaggle/working/ClaimsExtraction33', '/kaggle/working', '/kaggle/lib/kagglegym']\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.2.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.6.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.52.4)\nRequirement already satisfied: py_vncorenlp in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.26.4)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.7.2)\nRequirement already satisfied: underthesea in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (8.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 2)) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (0.33.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 3)) (4.67.1)\nRequirement already satisfied: pyjnius in /usr/local/lib/python3.11/dist-packages (from py_vncorenlp->-r requirements.txt (line 4)) (1.7.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 5)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 5)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 5)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 5)) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 5)) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 5)) (2.4.1)\nRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.15.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.5.1)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (3.6.0)\nRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from underthesea->-r requirements.txt (line 7)) (8.2.1)\nRequirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.11/dist-packages (from underthesea->-r requirements.txt (line 7)) (0.9.11)\nRequirement already satisfied: nltk>=3.8 in /usr/local/lib/python3.11/dist-packages (from underthesea->-r requirements.txt (line 7)) (3.9.1)\nRequirement already satisfied: underthesea_core==1.0.5 in /usr/local/lib/python3.11/dist-packages (from underthesea->-r requirements.txt (line 7)) (1.0.5)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->-r requirements.txt (line 3)) (1.1.5)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 5)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 5)) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->-r requirements.txt (line 5)) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->-r requirements.txt (line 5)) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2025.6.15)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->-r requirements.txt (line 5)) (2024.2.0)\n2025-10-02 10:30:04.242630: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759401004.264826    4212 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759401004.272032    4212 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nCUDA available: True\nGPU: Tesla P100-PCIE-16GB\nGPU Memory: 17.1 GB\n>> [1] Load & split dataset\n/kaggle/working/ClaimsExtraction33/scripts/train_contextualize.py:181: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  df = df.applymap(lambda x: x.strip('\"') if isinstance(x, str) else x)\n   Số dòng dữ liệu: 1038\n   Train: 830 | Valid: 104 | Test: 104\n>> Overlap Train-Valid: 0 samples\n>> Overlap Train-Test: 0 samples\n>> Overlap Valid-Test: 0 samples\n>> [2] Load tokenizer & model\n   Preprocessing train...\nMap: 100%|███████████████████████████| 830/830 [00:00<00:00, 2617.92 examples/s]\n   Preprocessing valid...\nMap: 100%|███████████████████████████| 104/104 [00:00<00:00, 2376.65 examples/s]\n   Preprocessing test...\nMap: 100%|███████████████████████████| 104/104 [00:00<00:00, 2695.27 examples/s]\n>> [3] Data collator\n>> [4] Load metrics\n>> [5] Training arguments\n/kaggle/working/ClaimsExtraction33/scripts/train_contextualize.py:364: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n>> [6] Start training...\n>> Cleared CUDA cache before training\n  0%|                                                   | 0/416 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n{'loss': 30.4306, 'grad_norm': 104.5225830078125, 'learning_rate': 2.963942307692308e-05, 'epoch': 0.05}\n{'loss': 4.0921, 'grad_norm': 3.1954543590545654, 'learning_rate': 2.8918269230769233e-05, 'epoch': 0.1}\n{'loss': 2.7764, 'grad_norm': 2.7262959480285645, 'learning_rate': 2.8197115384615384e-05, 'epoch': 0.14}\n{'loss': 2.5161, 'grad_norm': 2.126662254333496, 'learning_rate': 2.7475961538461537e-05, 'epoch': 0.19}\n{'loss': 2.4205, 'grad_norm': 3.0006356239318848, 'learning_rate': 2.6754807692307694e-05, 'epoch': 0.24}\n{'loss': 2.2947, 'grad_norm': 2.2158126831054688, 'learning_rate': 2.6033653846153848e-05, 'epoch': 0.29}\n{'loss': 2.2346, 'grad_norm': 2.54542875289917, 'learning_rate': 2.5312500000000002e-05, 'epoch': 0.34}\n{'loss': 2.0864, 'grad_norm': 2.6327364444732666, 'learning_rate': 2.4591346153846152e-05, 'epoch': 0.39}\n{'loss': 1.988, 'grad_norm': 5.376084327697754, 'learning_rate': 2.3870192307692306e-05, 'epoch': 0.43}\n{'loss': 1.9338, 'grad_norm': 4.420103073120117, 'learning_rate': 2.3149038461538463e-05, 'epoch': 0.48}\n{'loss': 1.874, 'grad_norm': 1.8044008016586304, 'learning_rate': 2.2427884615384617e-05, 'epoch': 0.53}\n{'loss': 1.8904, 'grad_norm': 2.810544967651367, 'learning_rate': 2.170673076923077e-05, 'epoch': 0.58}\n{'loss': 1.7762, 'grad_norm': 1.4488097429275513, 'learning_rate': 2.098557692307692e-05, 'epoch': 0.63}\n{'loss': 1.7384, 'grad_norm': 1.6754826307296753, 'learning_rate': 2.026442307692308e-05, 'epoch': 0.67}\n{'loss': 1.7107, 'grad_norm': 1.0636149644851685, 'learning_rate': 1.9543269230769232e-05, 'epoch': 0.72}\n{'loss': 1.7038, 'grad_norm': 1.1300652027130127, 'learning_rate': 1.8822115384615386e-05, 'epoch': 0.77}\n{'loss': 1.6847, 'grad_norm': 1.184044361114502, 'learning_rate': 1.8100961538461536e-05, 'epoch': 0.82}\n{'loss': 1.6866, 'grad_norm': 1.110960602760315, 'learning_rate': 1.7379807692307694e-05, 'epoch': 0.87}\n{'loss': 1.6528, 'grad_norm': 1.3862208127975464, 'learning_rate': 1.6658653846153847e-05, 'epoch': 0.92}\n{'loss': 1.6411, 'grad_norm': 1.0091685056686401, 'learning_rate': 1.59375e-05, 'epoch': 0.96}\n 50%|████████████████████▌                    | 208/416 [02:13<01:55,  1.81it/s]\n  0%|                                                   | 0/104 [00:00<?, ?it/s]\u001b[A\n  2%|▊                                          | 2/104 [00:00<00:33,  3.02it/s]\u001b[A\n  3%|█▏                                         | 3/104 [00:05<04:00,  2.38s/it]\u001b[A\n  4%|█▋                                         | 4/104 [00:06<02:48,  1.69s/it]\u001b[A\n  5%|██                                         | 5/104 [00:11<04:49,  2.93s/it]\u001b[A\n  6%|██▍                                        | 6/104 [00:16<06:02,  3.70s/it]\u001b[A\n  7%|██▉                                        | 7/104 [00:17<04:23,  2.71s/it]\u001b[A\n  8%|███▎                                       | 8/104 [00:22<05:37,  3.51s/it]\u001b[A\n  9%|███▋                                       | 9/104 [00:23<04:07,  2.60s/it]\u001b[A\n 10%|████                                      | 10/104 [00:24<03:07,  1.99s/it]\u001b[A\n 11%|████▍                                     | 11/104 [00:24<02:24,  1.55s/it]\u001b[A\n 12%|████▊                                     | 12/104 [00:29<04:06,  2.68s/it]\u001b[A\n 12%|█████▎                                    | 13/104 [00:35<05:17,  3.49s/it]\u001b[A\n 13%|█████▋                                    | 14/104 [00:40<06:05,  4.06s/it]\u001b[A\n 14%|██████                                    | 15/104 [00:45<06:33,  4.42s/it]\u001b[A\n 15%|██████▍                                   | 16/104 [00:46<04:48,  3.28s/it]\u001b[A\n 16%|██████▊                                   | 17/104 [00:51<05:37,  3.88s/it]\u001b[A\n 17%|███████▎                                  | 18/104 [00:57<06:09,  4.30s/it]\u001b[A\n 18%|███████▋                                  | 19/104 [00:57<04:29,  3.17s/it]\u001b[A\n 19%|████████                                  | 20/104 [00:58<03:23,  2.42s/it]\u001b[A\n 20%|████████▍                                 | 21/104 [01:03<04:30,  3.26s/it]\u001b[A\n 21%|████████▉                                 | 22/104 [01:04<03:22,  2.47s/it]\u001b[A\n 22%|█████████▎                                | 23/104 [01:04<02:34,  1.90s/it]\u001b[A\n 23%|█████████▋                                | 24/104 [01:09<03:52,  2.91s/it]\u001b[A\n 24%|██████████                                | 25/104 [01:15<04:44,  3.60s/it]\u001b[A\n 25%|██████████▌                               | 26/104 [01:20<05:19,  4.10s/it]\u001b[A\n 26%|██████████▉                               | 27/104 [01:25<05:41,  4.44s/it]\u001b[A\n 27%|███████████▎                              | 28/104 [01:30<05:55,  4.68s/it]\u001b[A\n 28%|███████████▋                              | 29/104 [01:31<04:15,  3.41s/it]\u001b[A\n 29%|████████████                              | 30/104 [01:36<04:51,  3.95s/it]\u001b[A\n 30%|████████████▌                             | 31/104 [01:37<03:34,  2.94s/it]\u001b[A\n 31%|████████████▉                             | 32/104 [01:37<02:39,  2.22s/it]\u001b[A\n 32%|█████████████▎                            | 33/104 [01:38<02:01,  1.70s/it]\u001b[A\n 33%|█████████████▋                            | 34/104 [01:38<01:33,  1.33s/it]\u001b[A\n 34%|██████████████▏                           | 35/104 [01:39<01:15,  1.10s/it]\u001b[A\n 35%|██████████████▌                           | 36/104 [01:39<01:03,  1.07it/s]\u001b[A\n 36%|██████████████▉                           | 37/104 [01:40<00:54,  1.22it/s]\u001b[A\n 37%|███████████████▎                          | 38/104 [01:40<00:47,  1.38it/s]\u001b[A\n 38%|███████████████▊                          | 39/104 [01:46<02:15,  2.09s/it]\u001b[A\n 38%|████████████████▏                         | 40/104 [01:46<01:43,  1.61s/it]\u001b[A\n 39%|████████████████▌                         | 41/104 [01:51<02:50,  2.70s/it]\u001b[A\n 40%|████████████████▉                         | 42/104 [01:52<02:08,  2.08s/it]\u001b[A\n 41%|█████████████████▎                        | 43/104 [01:52<01:37,  1.60s/it]\u001b[A\n 42%|█████████████████▊                        | 44/104 [01:58<02:44,  2.74s/it]\u001b[A\n 43%|██████████████████▏                       | 45/104 [02:03<03:25,  3.49s/it]\u001b[A\n 44%|██████████████████▌                       | 46/104 [02:08<03:51,  4.00s/it]\u001b[A\n 45%|██████████████████▉                       | 47/104 [02:13<04:09,  4.38s/it]\u001b[A\n 46%|███████████████████▍                      | 48/104 [02:19<04:20,  4.65s/it]\u001b[A\n 47%|███████████████████▊                      | 49/104 [02:19<03:09,  3.44s/it]\u001b[A\n 48%|████████████████████▏                     | 50/104 [02:25<03:34,  3.97s/it]\u001b[A\n 49%|████████████████████▌                     | 51/104 [02:30<03:51,  4.36s/it]\u001b[A\n 50%|█████████████████████                     | 52/104 [02:35<04:00,  4.62s/it]\u001b[A\n 51%|█████████████████████▍                    | 53/104 [02:36<02:52,  3.38s/it]\u001b[A\n 52%|█████████████████████▊                    | 54/104 [02:41<03:17,  3.95s/it]\u001b[A\n 53%|██████████████████████▏                   | 55/104 [02:41<02:21,  2.89s/it]\u001b[A\n 54%|██████████████████████▌                   | 56/104 [02:42<01:46,  2.21s/it]\u001b[A\n 55%|███████████████████████                   | 57/104 [02:42<01:20,  1.72s/it]\u001b[A\n 56%|███████████████████████▍                  | 58/104 [02:43<01:04,  1.40s/it]\u001b[A\n 57%|███████████████████████▊                  | 59/104 [02:44<00:53,  1.18s/it]\u001b[A\n 58%|████████████████████████▏                 | 60/104 [02:49<01:45,  2.41s/it]\u001b[A\n 59%|████████████████████████▋                 | 61/104 [02:50<01:20,  1.87s/it]\u001b[A\n 60%|█████████████████████████                 | 62/104 [02:50<01:01,  1.47s/it]\u001b[A\n 61%|█████████████████████████▍                | 63/104 [02:51<00:49,  1.21s/it]\u001b[A\n 62%|█████████████████████████▊                | 64/104 [02:51<00:41,  1.04s/it]\u001b[A\n 62%|██████████████████████████▎               | 65/104 [02:52<00:35,  1.11it/s]\u001b[A\n 63%|██████████████████████████▋               | 66/104 [02:53<00:30,  1.23it/s]\u001b[A\n 64%|███████████████████████████               | 67/104 [02:53<00:27,  1.36it/s]\u001b[A\n 65%|███████████████████████████▍              | 68/104 [02:54<00:23,  1.53it/s]\u001b[A\n 66%|███████████████████████████▊              | 69/104 [02:59<01:11,  2.04s/it]\u001b[A\n 67%|████████████████████████████▎             | 70/104 [03:00<00:54,  1.62s/it]\u001b[A\n 68%|████████████████████████████▋             | 71/104 [03:05<01:28,  2.69s/it]\u001b[A\n 69%|█████████████████████████████             | 72/104 [03:05<01:06,  2.07s/it]\u001b[A\n 70%|█████████████████████████████▍            | 73/104 [03:11<01:33,  3.01s/it]\u001b[A\n 71%|█████████████████████████████▉            | 74/104 [03:11<01:08,  2.27s/it]\u001b[A\n 72%|██████████████████████████████▎           | 75/104 [03:12<00:50,  1.74s/it]\u001b[A\n 73%|██████████████████████████████▋           | 76/104 [03:12<00:38,  1.39s/it]\u001b[A\n 74%|███████████████████████████████           | 77/104 [03:13<00:29,  1.10s/it]\u001b[A\n 75%|███████████████████████████████▌          | 78/104 [03:13<00:25,  1.02it/s]\u001b[A\n 76%|███████████████████████████████▉          | 79/104 [03:14<00:21,  1.15it/s]\u001b[A\n 77%|████████████████████████████████▎         | 80/104 [03:15<00:18,  1.28it/s]\u001b[A\n 78%|████████████████████████████████▋         | 81/104 [03:15<00:16,  1.41it/s]\u001b[A\n 79%|█████████████████████████████████         | 82/104 [03:20<00:46,  2.11s/it]\u001b[A\n 80%|█████████████████████████████████▌        | 83/104 [03:26<01:03,  3.03s/it]\u001b[A\n 81%|█████████████████████████████████▉        | 84/104 [03:31<01:14,  3.71s/it]\u001b[A\n 82%|██████████████████████████████████▎       | 85/104 [03:36<01:19,  4.17s/it]\u001b[A\n 83%|██████████████████████████████████▋       | 86/104 [03:37<00:55,  3.09s/it]\u001b[A\n 84%|███████████████████████████████████▏      | 87/104 [03:37<00:39,  2.34s/it]\u001b[A\n 85%|███████████████████████████████████▌      | 88/104 [03:38<00:29,  1.82s/it]\u001b[A\n 86%|███████████████████████████████████▉      | 89/104 [03:43<00:42,  2.84s/it]\u001b[A\n 87%|████████████████████████████████████▎     | 90/104 [03:48<00:49,  3.55s/it]\u001b[A\n 88%|████████████████████████████████████▊     | 91/104 [03:54<00:52,  4.05s/it]\u001b[A\n 88%|█████████████████████████████████████▏    | 92/104 [03:54<00:35,  3.00s/it]\u001b[A\n 89%|█████████████████████████████████████▌    | 93/104 [03:59<00:40,  3.68s/it]\u001b[A\n 90%|█████████████████████████████████████▉    | 94/104 [04:05<00:41,  4.15s/it]\u001b[A\n 91%|██████████████████████████████████████▎   | 95/104 [04:10<00:40,  4.48s/it]\u001b[A\n 92%|██████████████████████████████████████▊   | 96/104 [04:10<00:26,  3.33s/it]\u001b[A\n 93%|███████████████████████████████████████▏  | 97/104 [04:16<00:27,  3.90s/it]\u001b[A\n 94%|███████████████████████████████████████▌  | 98/104 [04:16<00:17,  2.88s/it]\u001b[A\n 95%|███████████████████████████████████████▉  | 99/104 [04:17<00:11,  2.22s/it]\u001b[A\n 96%|███████████████████████████████████████▍ | 100/104 [04:18<00:06,  1.73s/it]\u001b[A\n 97%|███████████████████████████████████████▊ | 101/104 [04:18<00:04,  1.40s/it]\u001b[A\n 98%|████████████████████████████████████████▏| 102/104 [04:19<00:02,  1.12s/it]\u001b[A\n 99%|████████████████████████████████████████▌| 103/104 [04:19<00:00,  1.03it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.6167304515838623, 'eval_rouge1': 57.69, 'eval_rouge2': 57.69, 'eval_rougeL': 57.69, 'eval_rougeLsum': 57.69, 'eval_bleu': 32.88, 'eval_f1': 34.49, 'eval_runtime': 265.9694, 'eval_samples_per_second': 0.391, 'eval_steps_per_second': 0.391, 'epoch': 1.0}\n 50%|████████████████████▌                    | 208/416 [06:39<01:55,  1.81it/s]\n100%|█████████████████████████████████████████| 104/104 [04:25<00:00,  2.24s/it]\u001b[A\n{'loss': 1.5839, 'grad_norm': 1.4028092622756958, 'learning_rate': 1.5216346153846153e-05, 'epoch': 1.01}\n{'loss': 1.6294, 'grad_norm': 1.0845801830291748, 'learning_rate': 1.4495192307692309e-05, 'epoch': 1.06}\n{'loss': 1.6111, 'grad_norm': 0.6490204930305481, 'learning_rate': 1.377403846153846e-05, 'epoch': 1.11}\n{'loss': 1.6173, 'grad_norm': 0.5878110527992249, 'learning_rate': 1.3052884615384616e-05, 'epoch': 1.15}\n{'loss': 1.5998, 'grad_norm': 1.3378655910491943, 'learning_rate': 1.2331730769230768e-05, 'epoch': 1.2}\n{'loss': 1.6371, 'grad_norm': 1.0557875633239746, 'learning_rate': 1.1610576923076924e-05, 'epoch': 1.25}\n{'loss': 1.6005, 'grad_norm': 0.9217499494552612, 'learning_rate': 1.0889423076923078e-05, 'epoch': 1.3}\n{'loss': 1.6083, 'grad_norm': 0.7734219431877136, 'learning_rate': 1.0168269230769231e-05, 'epoch': 1.35}\n{'loss': 1.6204, 'grad_norm': 1.6937932968139648, 'learning_rate': 9.447115384615385e-06, 'epoch': 1.4}\n{'loss': 1.6105, 'grad_norm': 0.6901532411575317, 'learning_rate': 8.725961538461539e-06, 'epoch': 1.44}\n{'loss': 1.5893, 'grad_norm': 1.413793683052063, 'learning_rate': 8.004807692307693e-06, 'epoch': 1.49}\n{'loss': 1.5938, 'grad_norm': 0.7189114689826965, 'learning_rate': 7.2836538461538465e-06, 'epoch': 1.54}\n{'loss': 1.5663, 'grad_norm': 0.5342481136322021, 'learning_rate': 6.5625e-06, 'epoch': 1.59}\n{'loss': 1.5926, 'grad_norm': 1.266216516494751, 'learning_rate': 5.841346153846154e-06, 'epoch': 1.64}\n{'loss': 1.6141, 'grad_norm': 0.6200252771377563, 'learning_rate': 5.120192307692308e-06, 'epoch': 1.68}\n{'loss': 1.6129, 'grad_norm': 1.1719517707824707, 'learning_rate': 4.399038461538462e-06, 'epoch': 1.73}\n{'loss': 1.5995, 'grad_norm': 0.6422819495201111, 'learning_rate': 3.6778846153846154e-06, 'epoch': 1.78}\n{'loss': 1.5606, 'grad_norm': 0.6137730479240417, 'learning_rate': 2.956730769230769e-06, 'epoch': 1.83}\n{'loss': 1.5994, 'grad_norm': 1.04953932762146, 'learning_rate': 2.235576923076923e-06, 'epoch': 1.88}\n{'loss': 1.61, 'grad_norm': 1.084245204925537, 'learning_rate': 1.514423076923077e-06, 'epoch': 1.93}\n{'loss': 1.582, 'grad_norm': 1.1318995952606201, 'learning_rate': 7.932692307692308e-07, 'epoch': 1.97}\n100%|█████████████████████████████████████████| 416/416 [08:58<00:00,  1.81it/s]\n  0%|                                                   | 0/104 [00:00<?, ?it/s]\u001b[A\n  2%|▊                                          | 2/104 [00:00<00:33,  3.02it/s]\u001b[A\n  3%|█▏                                         | 3/104 [00:01<00:38,  2.66it/s]\u001b[A\n  4%|█▋                                         | 4/104 [00:01<00:42,  2.37it/s]\u001b[A\n  5%|██                                         | 5/104 [00:02<00:50,  1.95it/s]\u001b[A\n  6%|██▍                                        | 6/104 [00:07<03:24,  2.08s/it]\u001b[A\n  7%|██▉                                        | 7/104 [00:08<02:37,  1.62s/it]\u001b[A\n  8%|███▎                                       | 8/104 [00:09<02:39,  1.66s/it]\u001b[A\n  9%|███▋                                       | 9/104 [00:10<02:05,  1.32s/it]\u001b[A\n 10%|████                                      | 10/104 [00:11<01:43,  1.10s/it]\u001b[A\n 11%|████▍                                     | 11/104 [00:11<01:26,  1.08it/s]\u001b[A\n 12%|████▊                                     | 12/104 [00:12<01:14,  1.24it/s]\u001b[A\n 12%|█████▎                                    | 13/104 [00:13<01:18,  1.16it/s]\u001b[A\n 13%|█████▋                                    | 14/104 [00:14<01:25,  1.06it/s]\u001b[A\n 14%|██████                                    | 15/104 [00:14<01:12,  1.22it/s]\u001b[A\n 15%|██████▍                                   | 16/104 [00:15<01:07,  1.31it/s]\u001b[A\n 16%|██████▊                                   | 17/104 [00:16<01:15,  1.15it/s]\u001b[A\n 17%|███████▎                                  | 18/104 [00:17<01:22,  1.04it/s]\u001b[A\n 18%|███████▋                                  | 19/104 [00:18<01:10,  1.20it/s]\u001b[A\n 19%|████████                                  | 20/104 [00:18<01:06,  1.27it/s]\u001b[A\n 20%|████████▍                                 | 21/104 [00:20<01:15,  1.10it/s]\u001b[A\n 21%|████████▉                                 | 22/104 [00:20<01:07,  1.22it/s]\u001b[A\n 22%|█████████▎                                | 23/104 [00:21<01:00,  1.34it/s]\u001b[A\n 23%|█████████▋                                | 24/104 [00:26<02:47,  2.10s/it]\u001b[A\n 24%|██████████                                | 25/104 [00:31<03:58,  3.02s/it]\u001b[A\n 25%|██████████▌                               | 26/104 [00:37<04:49,  3.71s/it]\u001b[A\n 26%|██████████▉                               | 27/104 [00:38<03:53,  3.03s/it]\u001b[A\n 27%|███████████▎                              | 28/104 [00:43<04:39,  3.68s/it]\u001b[A\n 28%|███████████▋                              | 29/104 [00:44<03:23,  2.71s/it]\u001b[A\n 29%|████████████                              | 30/104 [00:45<02:46,  2.25s/it]\u001b[A\n 30%|████████████▌                             | 31/104 [00:45<02:08,  1.76s/it]\u001b[A\n 31%|████████████▉                             | 32/104 [00:46<01:40,  1.39s/it]\u001b[A\n 32%|█████████████▎                            | 33/104 [00:46<01:19,  1.12s/it]\u001b[A\n 33%|█████████████▋                            | 34/104 [00:47<01:04,  1.08it/s]\u001b[A\n 34%|██████████████▏                           | 35/104 [00:47<00:55,  1.25it/s]\u001b[A\n 35%|██████████████▌                           | 36/104 [00:48<00:49,  1.37it/s]\u001b[A\n 36%|██████████████▉                           | 37/104 [00:49<00:45,  1.49it/s]\u001b[A\n 37%|███████████████▎                          | 38/104 [00:49<00:41,  1.60it/s]\u001b[A\n 38%|███████████████▊                          | 39/104 [00:54<02:10,  2.00s/it]\u001b[A\n 38%|████████████████▏                         | 40/104 [00:55<01:39,  1.56s/it]\u001b[A\n 39%|████████████████▌                         | 41/104 [00:55<01:18,  1.24s/it]\u001b[A\n 40%|████████████████▉                         | 42/104 [00:56<01:06,  1.07s/it]\u001b[A\n 41%|█████████████████▎                        | 43/104 [00:56<00:54,  1.12it/s]\u001b[A\n 42%|█████████████████▊                        | 44/104 [01:02<02:10,  2.18s/it]\u001b[A\n 43%|██████████████████▏                       | 45/104 [01:02<01:39,  1.68s/it]\u001b[A\n 44%|██████████████████▌                       | 46/104 [01:03<01:22,  1.42s/it]\u001b[A\n 45%|██████████████████▉                       | 47/104 [01:04<01:05,  1.16s/it]\u001b[A\n 46%|███████████████████▍                      | 48/104 [01:04<00:57,  1.03s/it]\u001b[A\n 47%|███████████████████▊                      | 49/104 [01:05<00:50,  1.10it/s]\u001b[A\n 48%|████████████████████▏                     | 50/104 [01:10<01:58,  2.19s/it]\u001b[A\n 49%|████████████████████▌                     | 51/104 [01:11<01:42,  1.94s/it]\u001b[A\n 50%|█████████████████████                     | 52/104 [01:12<01:23,  1.61s/it]\u001b[A\n 51%|█████████████████████▍                    | 53/104 [01:13<01:04,  1.27s/it]\u001b[A\n 52%|█████████████████████▊                    | 54/104 [01:13<00:51,  1.03s/it]\u001b[A\n 53%|██████████████████████▏                   | 55/104 [01:14<00:41,  1.19it/s]\u001b[A\n 54%|██████████████████████▌                   | 56/104 [01:14<00:37,  1.28it/s]\u001b[A\n 55%|███████████████████████                   | 57/104 [01:15<00:34,  1.36it/s]\u001b[A\n 56%|███████████████████████▍                  | 58/104 [01:16<00:32,  1.41it/s]\u001b[A\n 57%|███████████████████████▊                  | 59/104 [01:16<00:31,  1.44it/s]\u001b[A\n 58%|████████████████████████▏                 | 60/104 [01:17<00:29,  1.48it/s]\u001b[A\n 59%|████████████████████████▋                 | 61/104 [01:17<00:28,  1.53it/s]\u001b[A\n 60%|█████████████████████████                 | 62/104 [01:18<00:26,  1.60it/s]\u001b[A\n 61%|█████████████████████████▍                | 63/104 [01:19<00:25,  1.62it/s]\u001b[A\n 62%|█████████████████████████▊                | 64/104 [01:19<00:24,  1.60it/s]\u001b[A\n 62%|██████████████████████████▎               | 65/104 [01:20<00:24,  1.62it/s]\u001b[A\n 63%|██████████████████████████▋               | 66/104 [01:20<00:23,  1.64it/s]\u001b[A\n 64%|███████████████████████████               | 67/104 [01:21<00:22,  1.68it/s]\u001b[A\n 65%|███████████████████████████▍              | 68/104 [01:21<00:19,  1.80it/s]\u001b[A\n 66%|███████████████████████████▊              | 69/104 [01:22<00:18,  1.92it/s]\u001b[A\n 67%|████████████████████████████▎             | 70/104 [01:22<00:18,  1.80it/s]\u001b[A\n 68%|████████████████████████████▋             | 71/104 [01:28<01:04,  1.95s/it]\u001b[A\n 69%|█████████████████████████████             | 72/104 [01:28<00:49,  1.56s/it]\u001b[A\n 70%|█████████████████████████████▍            | 73/104 [01:30<00:45,  1.46s/it]\u001b[A\n 71%|█████████████████████████████▉            | 74/104 [01:30<00:35,  1.18s/it]\u001b[A\n 72%|██████████████████████████████▎           | 75/104 [01:31<00:28,  1.02it/s]\u001b[A\n 73%|██████████████████████████████▋           | 76/104 [01:31<00:23,  1.17it/s]\u001b[A\n 74%|███████████████████████████████           | 77/104 [01:32<00:19,  1.37it/s]\u001b[A\n 75%|███████████████████████████████▌          | 78/104 [01:32<00:18,  1.39it/s]\u001b[A\n 76%|███████████████████████████████▉          | 79/104 [01:33<00:17,  1.46it/s]\u001b[A\n 77%|████████████████████████████████▎         | 80/104 [01:34<00:15,  1.53it/s]\u001b[A\n 78%|████████████████████████████████▋         | 81/104 [01:34<00:14,  1.62it/s]\u001b[A\n 79%|█████████████████████████████████         | 82/104 [01:39<00:44,  2.02s/it]\u001b[A\n 80%|█████████████████████████████████▌        | 83/104 [01:40<00:32,  1.54s/it]\u001b[A\n 81%|█████████████████████████████████▉        | 84/104 [01:40<00:25,  1.25s/it]\u001b[A\n 82%|██████████████████████████████████▎       | 85/104 [01:41<00:20,  1.05s/it]\u001b[A\n 83%|██████████████████████████████████▋       | 86/104 [01:42<00:16,  1.09it/s]\u001b[A\n 84%|███████████████████████████████████▏      | 87/104 [01:42<00:13,  1.24it/s]\u001b[A\n 85%|███████████████████████████████████▌      | 88/104 [01:43<00:11,  1.34it/s]\u001b[A\n 86%|███████████████████████████████████▉      | 89/104 [01:48<00:31,  2.10s/it]\u001b[A\n 87%|████████████████████████████████████▎     | 90/104 [01:48<00:22,  1.62s/it]\u001b[A\n 88%|████████████████████████████████████▊     | 91/104 [01:49<00:17,  1.31s/it]\u001b[A\n 88%|█████████████████████████████████████▏    | 92/104 [01:50<00:12,  1.08s/it]\u001b[A\n 89%|█████████████████████████████████████▌    | 93/104 [01:50<00:10,  1.04it/s]\u001b[A\n 90%|█████████████████████████████████████▉    | 94/104 [01:56<00:22,  2.25s/it]\u001b[A\n 91%|██████████████████████████████████████▎   | 95/104 [01:56<00:16,  1.84s/it]\u001b[A\n 92%|██████████████████████████████████████▊   | 96/104 [01:57<00:11,  1.48s/it]\u001b[A\n 93%|███████████████████████████████████████▏  | 97/104 [01:58<00:08,  1.28s/it]\u001b[A\n 94%|███████████████████████████████████████▌  | 98/104 [01:58<00:06,  1.05s/it]\u001b[A\n 95%|███████████████████████████████████████▉  | 99/104 [01:59<00:04,  1.07it/s]\u001b[A\n 96%|███████████████████████████████████████▍ | 100/104 [02:00<00:03,  1.22it/s]\u001b[A\n 97%|███████████████████████████████████████▊ | 101/104 [02:00<00:02,  1.30it/s]\u001b[A\n 98%|████████████████████████████████████████▏| 102/104 [02:01<00:01,  1.50it/s]\u001b[A\n 99%|████████████████████████████████████████▌| 103/104 [02:01<00:00,  1.52it/s]\u001b[A\n                                                                                \u001b[A\n\u001b[A{'eval_loss': 1.5435490608215332, 'eval_rouge1': 81.62, 'eval_rouge2': 78.31, 'eval_rougeL': 79.63, 'eval_rougeLsum': 79.53, 'eval_bleu': 68.94, 'eval_f1': 37.71, 'eval_runtime': 123.4063, 'eval_samples_per_second': 0.843, 'eval_steps_per_second': 0.843, 'epoch': 2.0}\n100%|█████████████████████████████████████████| 416/416 [11:01<00:00,  1.81it/s]\n100%|█████████████████████████████████████████| 104/104 [02:02<00:00,  1.59it/s]\u001b[A\n{'train_runtime': 666.2132, 'train_samples_per_second': 2.492, 'train_steps_per_second': 0.624, 'train_loss': 2.5154932897824507, 'epoch': 2.0}\n100%|█████████████████████████████████████████| 416/416 [11:06<00:00,  1.60s/it]\n>> [7] Evaluate on test set\n100%|█████████████████████████████████████████| 104/104 [02:29<00:00,  1.43s/it]\n   Test metrics: {'test_loss': 1.5244269371032715, 'test_rouge1': 79.18, 'test_rouge2': 76.94, 'test_rougeL': 77.47, 'test_rougeLsum': 77.38, 'test_bleu': 71.62, 'test_f1': 42.68, 'test_runtime': 149.8617, 'test_samples_per_second': 0.694, 'test_steps_per_second': 0.694, 'epoch': 2.0}\n>> [8] Save predictions\n100%|█████████████████████████████████████████| 104/104 [02:29<00:00,  1.44s/it]\n   Predictions saved to './vit5-base-contextualize-claim/test_predictions.csv'\n>> [9] Save model & tokenizer\n>> DONE\nModel dir: /kaggle/working/ClaimsExtraction33/vit5-base-contextualize-claim\n--2025-10-02 10:46:25--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.dict\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 404 Not Found\n2025-10-02 10:46:25 ERROR 404: Not Found.\n\nmv: cannot stat 'wordsegmenter.dict': No such file or directory\nVnCoreNLP dir: /kaggle/working/ClaimsExtraction33/vncorenlp\nCURRENT_DIR: /kaggle/working/ClaimsExtraction33/Test\nBASE_DIR: /kaggle/working/ClaimsExtraction33\nsys.path:\n - /kaggle/working/ClaimsExtraction33\n - /kaggle/working/ClaimsExtraction33/Test\n - /kaggle/lib/kagglegym\n - /kaggle/lib\n - /usr/lib/python311.zip\n - /usr/lib/python3.11\n - /usr/lib/python3.11/lib-dynload\n - /usr/local/lib/python3.11/dist-packages\n - /usr/lib/python3/dist-packages\nFolders in BASE_DIR: ['contextualize_claims.py', 'Test', 'models', 'cpu_train_contextualize.py', 'vit5-base-contextualize-claim', 'colab_train.py', 'utils', 'rustup-init.exe', 'VnCoreNLP-1.1.1.jar.1', 'small_model_train.py', 'vncorenlp', 'py_vncorenlp', 'kaggle_train_contextualize.py', 'README.md', 'scripts', 'data', 'extract_claims.py', 'OpenJDK8U-jdk_x64_windows_hotspot_8u462b08.msi', 'requirements.txt', 'colab_setup.py', 'setup_vncorenlp.py']\n2025-10-02 10:46:32.264183: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759401992.286662    4251 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759401992.293677    4251 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nVNCORENLP_DIR: /kaggle/working/ClaimsExtraction33/py_vncorenlp\nJAR_PATH: /kaggle/working/ClaimsExtraction33/py_vncorenlp/VnCoreNLP-1.1.1.jar\n2025-10-02 10:46:36 INFO  WordSegmenter:24 - Loading Word Segmentation model\n2025-10-02 10:46:36 INFO  PosTagger:23 - Loading POS Tagging model\n2025-10-02 10:46:39 INFO  NerRecognizer:34 - Loading NER model\n2025-10-02 10:46:55 INFO  DependencyParser:32 - Loading Dependency Parsing model\n✅ VnCoreNLP loaded successfully\nProcessing 1 articles...\nTraceback (most recent call last):\n  File \"/kaggle/working/ClaimsExtraction33/Test/extract_claims.py\", line 57, in <module>\n    print(f\"\\n📰 Processing article {idx+1}/{len(df)} | ID: {article_id} | Title: {title}\")\n                                     ~~~^~\nTypeError: can only concatenate tuple (not \"int\") to tuple\nCURRENT_DIR: /kaggle/working/ClaimsExtraction33/Test\nBASE_DIR: /kaggle/working/ClaimsExtraction33\nsys.path:\n - /kaggle/working/ClaimsExtraction33\n - /kaggle/working/ClaimsExtraction33/Test\n - /kaggle/lib/kagglegym\n - /kaggle/lib\n - /usr/lib/python311.zip\n - /usr/lib/python3.11\n - /usr/lib/python3.11/lib-dynload\n - /usr/local/lib/python3.11/dist-packages\n - /usr/lib/python3/dist-packages\nFolders in ROOT_DIR: ['contextualize_claims.py', 'Test', 'models', 'cpu_train_contextualize.py', 'vit5-base-contextualize-claim', 'colab_train.py', 'utils', 'rustup-init.exe', 'VnCoreNLP-1.1.1.jar.1', 'small_model_train.py', 'vncorenlp', 'py_vncorenlp', 'kaggle_train_contextualize.py', 'README.md', 'scripts', 'data', 'extract_claims.py', 'OpenJDK8U-jdk_x64_windows_hotspot_8u462b08.msi', 'requirements.txt', 'colab_setup.py', 'setup_vncorenlp.py']\n>> Loading model from /kaggle/working/ClaimsExtraction33/vit5-base-contextualize-claim\n2025-10-02 10:47:09.152921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759402029.176779    4278 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759402029.183688    4278 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n>> Loaded 8 claims from /kaggle/working/ClaimsExtraction33/Test/data/contextualized_claims.csv\n>> DONE! Predictions saved to data/contextualized_claims_pred.csv\nTotal claims extracted: 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   ID                                              claim  \\\n0   1  Nhưng Nhật Bản vào vòng sau nhờ chỉ số fairpla...   \n1   1  Với tinh thần của những võ sĩ đạo Samurai, như...   \n2   1  Đó là lý do đội tuyển áo xanh được mệnh danh S...   \n3   1  Các cầu thủ Nhật vui vẻ sau trận thua Ba Lan 0...   \n4   1  Tại World Cup 2018, FIFA sẽ tính điểm fair pla...   \n\n                                             article  \n0  Thủ tướng Abe cúi đầu xin lỗi vì hành động phi...  \n1  Thủ tướng Abe cúi đầu xin lỗi vì hành động phi...  \n2  Thủ tướng Abe cúi đầu xin lỗi vì hành động phi...  \n3  Thủ tướng Abe cúi đầu xin lỗi vì hành động phi...  \n4  Thủ tướng Abe cúi đầu xin lỗi vì hành động phi...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>claim</th>\n      <th>article</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Nhưng Nhật Bản vào vòng sau nhờ chỉ số fairpla...</td>\n      <td>Thủ tướng Abe cúi đầu xin lỗi vì hành động phi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Với tinh thần của những võ sĩ đạo Samurai, như...</td>\n      <td>Thủ tướng Abe cúi đầu xin lỗi vì hành động phi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Đó là lý do đội tuyển áo xanh được mệnh danh S...</td>\n      <td>Thủ tướng Abe cúi đầu xin lỗi vì hành động phi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Các cầu thủ Nhật vui vẻ sau trận thua Ba Lan 0...</td>\n      <td>Thủ tướng Abe cúi đầu xin lỗi vì hành động phi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Tại World Cup 2018, FIFA sẽ tính điểm fair pla...</td>\n      <td>Thủ tướng Abe cúi đầu xin lỗi vì hành động phi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2}]}